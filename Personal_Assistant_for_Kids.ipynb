{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3915f53-78fc-4959-abff-b0c1a12729de",
   "metadata": {},
   "source": [
    "# Personal Assistant for Children with Special Needs\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Jupyter notebook documents the creation of a \"Virtual Friend\" personal assistant application. It is designed specifically for children  with Attention Deficit Hyperactivity Disorder (ADHD). Using advanced technologies like Large Language Models (LLM) and Natural Language Processing (NLP), this tool is aim to enhance communication skills and maintain engagement in everyday social interactions through interactive support.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fde9b5-24cb-42e0-8252-56f1e969e8dd",
   "metadata": {},
   "source": [
    "### 1. Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c918ec6-8ce6-49f2-8d85-f6e8840a5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install openai==1.23.2\n",
    "# !pip install flask_cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "299dfa97-7f08-4ca9-88b1-dc8f49c1b796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.2\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "print(openai.__version__)\n",
    "# https://platform.openai.com/docs/assistants/overview?context=with-streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee901c-4592-499a-9d1e-3e7cdd1b1020",
   "metadata": {},
   "source": [
    "### 2. API Client Initialization and Assistant Configuration\n",
    "\n",
    "Initiate the OpenAI API client and set up the virtual assistant name and ID for future interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbcac389-f12b-4dd5-87bf-736ad13b481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "'''\n",
    "I didn't want to expose my api keys that's why I used dotenv library\n",
    ".env file needs to be added with the content\n",
    "\n",
    "OPENAI_API_KEY=\"XXXXXX\"\n",
    "''' \n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "     api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "assistant_name = \"Virtual Friend\"\n",
    "assistant_id = \"asst_waiBYAHIZoJqFZWa4mzJ9ivX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea3a7b-fdad-4de8-98eb-97e2a3c5c68e",
   "metadata": {},
   "source": [
    "### 3. Create the Personal Assistant\n",
    "\n",
    "The function is crucial for setting up the assistant with specific settings tailored to the needs of children with ADHD, using the capabilities of OpenAI's GPT-4 Turbo model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3521f3-79b2-4bee-850e-b447d279335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_assistant():\n",
    "    assistant = client.beta.assistants.create(\n",
    "      name=\"Virtual Friend\",\n",
    "      instructions=\"\"\"You are a supportive companion for an 8-year-old child with ADHD. \n",
    "      Engage in conversation with him to help maintain focus on the same topic.\n",
    "      If he strays from the subject, redirect his attention back to the topic in an engaging manner.\n",
    "      \"\"\",\n",
    "      tools=[{\"type\": \"code_interpreter\"}],\n",
    "      model=\"gpt-4-turbo\",\n",
    "    )\n",
    "    return assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9692c-1dfa-4212-9b53-52e370cb3b75",
   "metadata": {},
   "source": [
    "### 4. Retrieve the Personal Assistant\n",
    "\n",
    "This function retrieves an existing virtual assistant using its ID or creates a new one if it doesn't exist.So we can ensure the assistant is always available for user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f599e7-a657-43ec-92a2-1bee25238821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assistant():\n",
    "    if assistant_id != None:\n",
    "        return client.beta.assistants.retrieve(assistant_id=assistant_id)\n",
    "    \n",
    "    for assistant in client.beta.assistants.list().data:\n",
    "        print(assistant.name, assistant.id)\n",
    "    \n",
    "        if assistant.name == assistant_name:\n",
    "            # return assistant.id\n",
    "            print(assistant.id)\n",
    "            return client.beta.assistants.retrieve(assistant_id=assistant.id)\n",
    "\n",
    "    assistant = create_assistant()\n",
    "    print (assistant.id)\n",
    "    return assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4bfd37e-085b-49d1-b333-13c9bc55a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = get_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6394df0d-6c88-4d5d-8566-f78d244d7ee9",
   "metadata": {},
   "source": [
    "### 5. Handling Tokens\n",
    "This function is used to collect the token and later sent to the client word by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5d83bc1-6416-410d-8315-a955d85b8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "def stream(token):\n",
    "    global tokens\n",
    "    tokens.append(token)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a27ec0-7a10-4d9b-a723-46845f2d0649",
   "metadata": {},
   "source": [
    "### 6. Create a EventHandler Class \n",
    "\n",
    "First, create an EventHandler class to define how to handle events in the response stream.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762fa446-aeaf-4d86-81cc-66462fc23243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    " \n",
    "class EventHandler(AssistantEventHandler):    \n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    # print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "    pass\n",
    "      \n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    # print(delta.value, end=\"\", flush=True)\n",
    "    stream(delta.value)\n",
    "    self.on_token(delta.value)\n",
    "\n",
    "  def on_token(self, token):\n",
    "      pass\n",
    "\n",
    "  def on_end(self):\n",
    "    # print('ended')\n",
    "    stream(None)\n",
    "      \n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\noutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c9823-bd24-400f-b59d-63946ac824eb",
   "metadata": {},
   "source": [
    "### 7. Create a Thread\n",
    "A Thread represents a conversation between a user and one or more Assistants. You can create a Thread whenever a user, or your AI application, initiates a conversation with your Assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21764e1d-6202-469e-89e3-61b052b5dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved into the start function\n",
    "#thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166680bb-5488-4cc0-90b0-b40d96d81a88",
   "metadata": {},
   "source": [
    "### 8. Adding Message to the Thread and Create a Run\n",
    "Initiate a conversation by adding messages to the thread as the user asks questions.\n",
    "\n",
    "Note: Intentionally, I inject a prompt \"Hi\" to initiate a conversation but hide it from the user so it appears like initiated the conversation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8049afbf-2453-466a-8ec7-99e6e5afa3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    thread = client.beta.threads.create()\n",
    "    \n",
    "    first = True\n",
    "    while True:\n",
    "        if first == True:\n",
    "            first = False\n",
    "            user_input = 'Hi'\n",
    "        else:\n",
    "            user_input = input()\n",
    "\n",
    "        if user_input == \"\":\n",
    "            print(\"--- exiting\")\n",
    "            break\n",
    " \n",
    "        message = client.beta.threads.messages.create(\n",
    "          thread_id=thread.id,\n",
    "          role=\"user\",\n",
    "          content=user_input\n",
    "        )\n",
    "        \n",
    "        \n",
    "        with client.beta.threads.runs.stream(\n",
    "          thread_id=thread.id,\n",
    "          assistant_id=assistant.id,\n",
    "          event_handler=EventHandler(),\n",
    "        ) as stream:\n",
    "          stream.on_token = lambda word: print(word, end=\"\", flush=True)\n",
    "          stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f7ad235-b47e-4d9c-baed-ec200d17da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the actual dialog between 8-years-old boy and the Personal Assistant on 5/2/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fcf55e8-ad1a-4982-9861-b8466c2161d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39783a2f-aba8-4b7f-a755-98f881185389",
   "metadata": {},
   "source": [
    "### 9. Generating Responses for Web Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22b6fd49-5c77-418f-bf3e-ca8a4f9b06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate(): \n",
    "    global tokens\n",
    "    while True:\n",
    "      if len(tokens) > 0:\n",
    "        item = tokens.pop(0)\n",
    "        if item == None: \n",
    "            break\n",
    "        yield item\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "def prompt(user_input, thread):\n",
    "    message = client.beta.threads.messages.create(\n",
    "          thread_id=thread.id,\n",
    "          role=\"user\",\n",
    "          content=user_input\n",
    "        )\n",
    "\n",
    "    \n",
    "     \n",
    "    with client.beta.threads.runs.stream(\n",
    "      thread_id=thread.id,\n",
    "      assistant_id=assistant.id,\n",
    "      event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "      # stream.on_token = sentence \n",
    "\n",
    "      stream.until_done()\n",
    "\n",
    "    return None\n",
    "\n",
    "# thread = client.beta.threads.create()\n",
    "# prompt('how are you', thread)\n",
    "# for i in generate():\n",
    "#     print(i, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3becf-a961-4ef3-8e45-0ddbd9742f89",
   "metadata": {},
   "source": [
    "### 10. Flask Web Application Setup\n",
    "I've included this step to demonstrate how the personal assistant operates in a web-based environment for the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1d69c-b5dc-47a5-910a-b4f71e2a5c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [15/May/2024 19:48:49] \"GET /reset HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/May/2024 19:48:55] \"GET /query?query=hi HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/May/2024 19:48:57] \"GET /query?query=hi HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/May/2024 19:50:29] \"GET /query?query=and%20right%20till%20then%20you%20can%20focus%20on%20that HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect, session, Response, jsonify\n",
    "from flask_cors import CORS, cross_origin\n",
    "app = Flask(__name__)\n",
    "cors = CORS(app)\n",
    "app.config['CORS_HEADERS'] = 'Content-Type'\n",
    "\n",
    "thread = None \n",
    "\n",
    "def reset_thread():\n",
    "    global thread\n",
    "    thread = client.beta.threads.create()\n",
    "\n",
    "reset_thread()\n",
    "\n",
    "@app.route('/reset', methods=['GET'])\n",
    "def reset():\n",
    "    reset_thread()\n",
    "    return jsonify(True)\n",
    "\n",
    "@app.route('/query', methods=['GET'])\n",
    "def handle_get():\n",
    "    query = request.args['query']\n",
    "    # print(query)\n",
    "    prompt(query, thread)\n",
    "     \n",
    "    return Response(generate(), mimetype='text/event-stream')\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288ebbb-0911-4beb-9f7c-357e703333f6",
   "metadata": {},
   "source": [
    "#### SUMMARY \n",
    "\n",
    "In this project, I developed a virtual personal assistant to help children with Attention-Deficit Hyperactivity Disorder (ADHD). Using OpenAI's Assistant API, the assistant aims to enhance verbal communication skills and keep children engaged by sustaining their focus during interactions. \n",
    "\n",
    "The assistant is instructed to maintain engaging conversations that align with children's interests while subtly steering them to stay on topic. The assistant enables real-time understanding and reaction to the child's input. \n",
    "\n",
    "In testing, the personal assistant demonstrates understanding and responds appropriately, even to inputs that include emojis. Its ability to ask follow-up questions, provide enlightening insights, and maintain specific contexts conversationally shows its adaptability and customization potential.\n",
    "\n",
    "\n",
    "However, designing this tool for children with ADHD presents several challenges, especially in providing precise instructions to foster meaningful dialogues between the child and the assistant. It's crucial to give strategic instructions that engage the child's interests while gently guiding them to stay focused on the current topic.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada781c-4529-4535-8c0e-f28354144482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b3236-983f-4778-a560-9ee2e94e1fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a0599-3448-46c2-a033-e3713cc05aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923d8af-95a2-4c92-a855-39ba8513b604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
